# Chapter 9. Human + Agent Collaboration

**Human supervises the AI**

---

#### 1. What does “human + agent collaboration” mean?

Till now, we mostly let agents talk:

* One agent answers questions
* Two or three agents discuss and decide

Now we add an important layer: **you, the human, are the boss**.

* The AI agents **do the work**
* But **you review and approve** their answers
* If you don’t like something, you tell them to **change or improve it**

This is called **human-in-the-loop**.
Think of it as **AI = assistant, human = final decision maker**.

---

#### 2. Real-life picture: Student supervising AI for math

Imagine a **student** using a math helper:

1. The student asks:
   “Solve: 2x + 3 = 11. Show steps.”

2. The AI agent replies with a solution.

3. The student checks:

   * “Are the steps correct?”
   * “Is it easy to understand?”

4. If the answer is **not clear**, the student says:
   “Explain step 2 more slowly.”
   or
   “Use smaller numbers as examples.”

So the flow becomes:

> Agent proposes → Human checks → Human approves or asks to revise

In Autogen, you can design the system so that:

* After each agent response,
* The **user must approve** before the conversation continues.

---

#### 3. Why human supervision is important

This pattern is very useful when:

* You teach students (math, science, coding)
* You handle **sensitive topics** (health, finance, law)
* You run **business workflows** (contracts, prices, policies)

Because:

* AI can **make mistakes**
* AI may **skip important details**
* AI doesn’t know your exact **preferences** unless you guide it

With **human + agent collaboration**:

* AI does the “heavy work”
* Human reviews and **keeps control**

You get **speed + safety**.

---

#### 4. How supervision looks in Autogen (simple idea)

In Autogen, there is often a **UserProxyAgent** or similar component that:

* Represents the **human user**
* Can be set to **ask for your input** between steps
* Can decide whether to **continue or stop**

You can design a loop like:

1. Agent writes an answer
2. Show answer to user
3. Ask user: “Approve? (yes/no)”
4. If “no”, ask agent to revise
5. If “yes”, move on or end chat

Conceptual example:

```python
from autogen import AssistantAgent, UserProxyAgent

# 1. The math helper agent (does the work)
math_agent = AssistantAgent(
    name="math_helper",
    system_message=(
        "You are a friendly math tutor. "
        "Explain every step very clearly for beginners."
    ),
    llm_config={"model": "gpt-4o-mini", "temperature": 0.2}
)

# 2. The user proxy (represents human, asks for approval)
user_agent = UserProxyAgent(
    name="human_supervisor",
    human_input_mode="ALWAYS",  # Always ask the real user for input
)

# 3. Start a supervised conversation
initial_question = "Solve 2x + 3 = 11 step by step. Explain like I am 12 years old."

# Human starts the chat with the math agent
user_agent.initiate_chat(
    math_agent,
    message=initial_question
)

# In many Autogen setups, after each response, the UserProxyAgent
# will pause and ask you (in the console):
#   - whether to continue,
#   - or to modify the message,
#   - or to stop.
#
# You, the human, effectively "approve" each step.
```

In simple words:

* `math_helper` = AI tutor
* `human_supervisor` = you, through the terminal or UI
* After each answer, the system can **wait for your approval** before continuing.

In a more customized script, you could even do:

```python
# Pseudo-code to show the idea
reply = math_agent.generate_reply(messages=[{"role": "user", "content": initial_question}])
print("AI answer:\n", reply)

approve = input("Do you approve this answer? (yes/no): ").strip().lower()

if approve != "yes":
    # Ask AI to improve or correct
    followup = "Please improve your previous answer. Make it clearer and check the steps."
    reply = math_agent.generate_reply(messages=[
        {"role": "user", "content": initial_question},
        {"role": "assistant", "content": reply},
        {"role": "user", "content": followup}
    ])
    print("Updated AI answer:\n", reply)
```

Here:

* You **see** the answer
* You **type yes/no**
* The AI **updates** its answer if needed

This is a very simple and clear way to keep the human in charge.

---

#### 5. Where can you use this pattern?

Some ideas:

* **Student learning app**

  * AI shows solution → student approves or asks for simpler explanation

* **Content writing**

  * AI drafts email/blog → human approves, edits, or asks for tone change

* **Code generation**

  * AI writes function → human reads → approves or asks to add comments/tests

* **Clinic or hospital assistant**

  * AI drafts summary → doctor reviews → approves before sending to patient

In all cases, **nothing goes out** without human approval.

---

#### 6. Takeaway

* Human + agent collaboration means **you are the supervisor**.
* AI agents do the work, but **you approve each response**.
* This is safer and more reliable, especially for teaching and sensitive areas.
* In Autogen, you can control this with a **UserProxyAgent** or your own approval loop.

This pattern is core to **responsible agentic AI**.

---

### Codex task for this chapter

**Instruction for Codex:**

> “Create agent code where user approves each response. Use a simple example where a math-tutor agent solves a problem, then the user must type ‘yes’ to approve or ‘no’ to ask the agent to improve the explanation. Add clear comments for beginners.”
