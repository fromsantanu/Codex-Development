# **Chapter 40. Complete Source Code + Documentation**

In this chapter, we will put everything together for the
**“Intelligent Report Generator Agent”** from Chapter 39.

You will see:

* A clean **project folder structure**
* A practical **README**
* Simple **API docs**
* A short **User Guide**
* A **Setup Guide**
* Basic **test cases**
* Simple text **diagrams**
* How to ask **Codex** to improve this whole project

Think of this chapter as a “starter kit” you can copy, adapt, and grow.

---

## 1. Project Folder Structure

Here is a suggested layout for your full project:

```text
report-agent/
├─ README.md
├─ requirements.txt
├─ .env.example
├─ Dockerfile
├─ app/
│  ├─ __init__.py
│  ├─ config.py
│  ├─ llm_client.py
│  ├─ tools.py
│  ├─ rag.py
│  ├─ graph.py
│  ├─ server.py
│  └─ prompts/
│     ├─ report_system_v1.md
│     └─ report_system_v2.md
├─ tests/
│  ├─ __init__.py
│  ├─ test_tools.py
│  ├─ test_graph.py
│  └─ test_api.py
└─ diagrams/
   ├─ architecture.txt
   └─ sequence.txt
```

We’ll fill in the key parts now.

---

## 2. README.md (Main Project Overview)

You can start with something like this:

````markdown
# Intelligent Report Generator Agent

This project is an end-to-end **agentic system** that creates
weekly business reports automatically.

It uses:

- LangChain (LLM and tools)
- LangGraph (workflow / graph)
- A simple RAG retriever
- FastAPI + LangServe (API)
- Docker (deployment)
- Pytest (tests)

The agent:

1. Fetches sales data from an API (dummy in this demo)
2. Analyzes simple statistics (total, average)
3. Generates insights using an LLM
4. Uses RAG to bring in context documents
5. Builds a final report in Markdown

---
## Features

- Clear folder structure
- Config via `.env`
- Single `/weekly-report` endpoint
- Easy to containerize
- Example tests for tools, graph, and API

---
## Quick Start

```bash
git clone <your-repo-url>
cd report-agent
cp .env.example .env
# Edit .env with your own keys

pip install -r requirements.txt
uvicorn app.server:app --reload --port 8000
````

Open in browser:

* API root: [http://localhost:8000](http://localhost:8000)
* Weekly report endpoint: POST [http://localhost:8000/weekly-report](http://localhost:8000/weekly-report)

---

## Tech Stack

* Python 3.11+
* FastAPI
* LangChain
* LangGraph
* LangServe
* httpx
* uvicorn
* pytest

````

You can expand this later, but this is enough to start.

---

## 3. requirements.txt

Example minimal dependencies:

```text
fastapi
uvicorn
httpx
langchain
langchain-openai
langgraph
langserve
python-dotenv
faiss-cpu     # or chromadb, depending on your choice
pytest
````

(Adjust as needed based on the actual libraries you use.)

---

## 4. Config and LLM Client

### `app/config.py`

```python
import os
from dotenv import load_dotenv

load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
SALES_API_URL = os.getenv("SALES_API_URL", "http://localhost:9000/sales")
RAG_VECTOR_DIR = os.getenv("RAG_VECTOR_DIR", "./data/vectorstore")
REPORT_MODEL = os.getenv("REPORT_MODEL", "gpt-4o-mini")
```

### `.env.example`

```env
OPENAI_API_KEY=sk-xxx
SALES_API_URL=http://localhost:9000/sales
RAG_VECTOR_DIR=./data/vectorstore
REPORT_MODEL=gpt-4o-mini
```

### `app/llm_client.py`

```python
from langchain_openai import ChatOpenAI
from app.config import REPORT_MODEL, OPENAI_API_KEY

def get_llm():
    return ChatOpenAI(
        model=REPORT_MODEL,
        api_key=OPENAI_API_KEY,
        temperature=0.2,
    )
```

---

## 5. Tools: Data Fetch + Simple Stats

### `app/tools.py`

```python
import httpx
from app.config import SALES_API_URL

async def fetch_sales_data():
    """
    Fetch sales data from the backend API.
    Expected format: list of { "amount": number, "date": "YYYY-MM-DD", ... }
    """
    async with httpx.AsyncClient() as client:
        resp = await client.get(SALES_API_URL)
        resp.raise_for_status()
        return resp.json()

def calculate_basic_stats(sales_data: list[dict]) -> dict:
    """
    Calculate simple stats: total and average.
    """
    amounts = [item["amount"] for item in sales_data if "amount" in item]
    if not amounts:
        return {"total": 0, "average": 0, "count": 0}

    total = sum(amounts)
    avg = total / len(amounts)
    return {"total": total, "average": avg, "count": len(amounts)}
```

---

## 6. RAG Setup (Very Simple Skeleton)

### `app/rag.py`

For now, we can keep a very simple dummy retriever (you can later attach FAISS/Chroma):

```python
from typing import List

# In a real system, replace this with a vector store retriever.
DUMMY_DOCS = [
    "Watch inventory levels for popular items.",
    "Seasonal demand can affect weekly sales.",
    "Delivery delays can impact customer satisfaction."
]

def retrieve_context(query: str, k: int = 3) -> List[str]:
    """
    Dummy RAG: returns top-k static lines.
    Replace with real vector retrieval.
    """
    return DUMMY_DOCS[:k]
```

---

## 7. LangGraph Workflow

### `app/graph.py`

```python
from typing import TypedDict
from langgraph.graph import StateGraph, END
from app.tools import fetch_sales_data, calculate_basic_stats
from app.rag import retrieve_context
from app.llm_client import get_llm

llm = get_llm()

class ReportState(TypedDict, total=False):
    sales_data: list
    analysis: dict
    insights: str
    rag_info: str
    final_report: str

async def node_fetch(state: ReportState) -> ReportState:
    data = await fetch_sales_data()
    state["sales_data"] = data
    return state

def node_analyze(state: ReportState) -> ReportState:
    stats = calculate_basic_stats(state["sales_data"])
    state["analysis"] = stats
    return state

async def node_insights(state: ReportState) -> ReportState:
    prompt = f"""
You are a business analyst.

Sales data: {state["sales_data"]}
Stats: {state["analysis"]}

Give 5 key insights in short bullet points.
Do not invent numbers.
"""
    result = await llm.ainvoke(prompt)
    state["insights"] = result.content
    return state

async def node_rag(state: ReportState) -> ReportState:
    docs = retrieve_context("weekly sales risks and context")
    state["rag_info"] = "\n".join(docs)
    return state

async def node_final(state: ReportState) -> ReportState:
    prompt = f"""
Create a weekly sales report in Markdown with sections:
- Summary Numbers
- Key Insights
- Context / Risks

Use this data:
Stats: {state["analysis"]}
Insights: {state["insights"]}
Context: {state["rag_info"]}
"""
    result = await llm.ainvoke(prompt)
    state["final_report"] = result.content
    return state

def build_graph():
    graph = StateGraph(ReportState)

    graph.add_node("fetch", node_fetch)
    graph.add_node("analyze", node_analyze)
    graph.add_node("insights", node_insights)
    graph.add_node("rag", node_rag)
    graph.add_node("final", node_final)

    graph.set_entry_point("fetch")

    graph.add_edge("fetch", "analyze")
    graph.add_edge("analyze", "insights")
    graph.add_edge("insights", "rag")
    graph.add_edge("rag", "final")
    graph.add_edge("final", END)

    return graph.compile()
```

---

## 8. FastAPI + LangServe Server

### `app/server.py`

```python
from fastapi import FastAPI
from langserve import add_routes
from app.graph import build_graph

app = FastAPI(title="Report Agent Service")

report_app = build_graph()

async def run_report(_: str = ""):
    """
    Entry function for LangServe.
    Input is unused in this simple version, but kept for future extension.
    """
    result = await report_app.invoke({})
    return result["final_report"]

add_routes(app, run_report, path="/weekly-report")

@app.get("/")
def root():
    return {"message": "Report Agent is running", "endpoint": "/weekly-report"}
```

---

## 9. API Docs (Simple)

You can describe the API like this (in `README.md` or a separate `API_DOCS.md`):

````markdown
# API Documentation

## POST /weekly-report

Generate a weekly sales report.

### Request

**URL**: `/weekly-report`  
**Method**: POST  
**Content-Type**: `application/json`

#### Body (optional)

```json
{
  "input": "optional free text, currently unused"
}
````

### Response

**Status**: 200 OK

```json
{
  "output": "# Weekly Sales Report\n\n## Summary Numbers..."
}
```

The `output` field contains the report in Markdown format.

---

## GET /

Health check endpoint.

### Response

```json
{
  "message": "Report Agent is running",
  "endpoint": "/weekly-report"
}
```

````

---

## 10. User Guide (Very Simple Steps)

You can put this in `USER_GUIDE.md` or inside the README.

```markdown
# User Guide – Intelligent Report Generator Agent

## 1. Start the Service

```bash
uvicorn app.server:app --reload --port 8000
````

## 2. Generate a Report

Use curl or any HTTP client:

```bash
curl -X POST http://localhost:8000/weekly-report \
  -H "Content-Type: application/json" \
  -d '{"input": "generate weekly sales report"}'
```

You will receive a JSON response with a Markdown report in `output`.

## 3. View Report

* Copy the Markdown into any Markdown viewer
* Or paste it into tools like VS Code, Obsidian, etc.
* Later, you can convert it to PDF or HTML

## 4. Typical Use Cases

* Weekly sales review meeting
* Quick snapshot for management
* Automated scheduled reporting

````

---

## 11. Setup Guide

Add a separate section or file `SETUP.md`:

```markdown
# Setup Guide

## 1. Requirements

- Python 3.11+
- pip
- (Optional) Docker

## 2. Installation

```bash
git clone <your-repo-url>
cd report-agent
python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate
pip install -r requirements.txt
cp .env.example .env
# Edit .env with your OpenAI API key and backend URL
````

## 3. Running Locally

```bash
uvicorn app.server:app --reload --port 8000
```

## 4. Docker

Build:

```bash
docker build -t report-agent:latest .
```

Run:

```bash
docker run --env-file .env -p 8000:8000 report-agent:latest
```

````

---

## 12. Dockerfile

```dockerfile
FROM python:3.11-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

EXPOSE 8000

CMD ["uvicorn", "app.server:app", "--host", "0.0.0.0", "--port", "8000"]
````

---

## 13. Test Cases (Pytest Examples)

### `tests/test_tools.py`

```python
from app.tools import calculate_basic_stats

def test_calculate_basic_stats_normal():
    data = [{"amount": 100}, {"amount": 200}, {"amount": 300}]
    stats = calculate_basic_stats(data)
    assert stats["total"] == 600
    assert stats["average"] == 200
    assert stats["count"] == 3

def test_calculate_basic_stats_empty():
    stats = calculate_basic_stats([])
    assert stats["total"] == 0
    assert stats["average"] == 0
    assert stats["count"] == 0
```

### `tests/test_graph.py`

```python
import asyncio
from app.graph import build_graph

def test_graph_flow_simple():
    app_graph = build_graph()
    result = asyncio.run(app_graph.invoke({}))
    assert "final_report" in result
    assert isinstance(result["final_report"], str)
    assert len(result["final_report"]) > 0
```

### `tests/test_api.py`

```python
from fastapi.testclient import TestClient
from app.server import app

client = TestClient(app)

def test_root_endpoint():
    resp = client.get("/")
    assert resp.status_code == 200
    data = resp.json()
    assert "message" in data

def test_weekly_report_endpoint():
    resp = client.post("/weekly-report", json={"input": "test"})
    assert resp.status_code == 200
    data = resp.json()
    assert "output" in data
    assert isinstance(data["output"], str)
```

Run tests:

```bash
pytest -q
```

---

## 14. Diagrams (Text-Based)

### `diagrams/architecture.txt`

```text
[ Client / Frontend ]
          |
          v
  POST /weekly-report
          |
   [ FastAPI + LangServe ]
          |
   [ Report Agent (LangGraph) ]
          |
   -------------------------------
   |           |                |
[Tools]     [LLM]            [RAG]
fetch       insights       context docs
sales       + final       (dummy or real)
data        report
```

### `diagrams/sequence.txt`

```text
User → /weekly-report (POST)
    → FastAPI → report_app.invoke({})

report_app:
  1. node_fetch     → fetch_sales_data()
  2. node_analyze   → calculate_basic_stats()
  3. node_insights  → llm.ainvoke(prompt)
  4. node_rag       → retrieve_context()
  5. node_final     → llm.ainvoke(report_prompt)

→ Final state["final_report"]
→ FastAPI → JSON {"output": "<markdown report>"}
→ User
```

---

## 15. Codex-Generated Improvements (How to Use Codex Here)

Once this base project exists, you can ask Codex to:

1. **Improve folder structure**

   > “Codex, here is my repo structure and code. Suggest a better separation of `tools`, `rag`, and `graph` modules. Refactor code accordingly.”

2. **Improve prompts**

   > “Codex, improve my report-generation prompt to be more consistent, enforce headings, and avoid invented numbers. Suggest v2 prompt in Markdown and save as `report_system_v2.md`.”

3. **Add error handling**

   > “Codex, add proper error handling around the `fetch_sales_data` call and make the API return a clear 503 error if the backend is down.”

4. **Add more tests**

   > “Codex, generate more pytest tests for edge cases: no sales data, very large sales data, and invalid API responses.”

5. **Add logging**

   > “Codex, introduce a simple logging setup (logging module) that logs every report generation with total, average, and time taken.”

6. **Optimize RAG**

   > “Codex, replace the dummy `retrieve_context` with a FAISS-based retriever using local documents. Generate setup code and notes for indexing documents.”

By repeatedly asking Codex to “refactor”, “harden”, “add tests”, and “improve prompts”, your project becomes more and more production-ready.

---

## 16. Chapter Summary

In this chapter, we:

* Designed a **complete repo structure**
* Wrote a clear **README**, **API docs**, **User Guide**, and **Setup Guide**
* Created **source code** for:

  * Config, tools, RAG, Graph, Server
* Added **test cases** to keep things stable
* Added simple text **diagrams** for understanding
* Showed how **Codex** can improve everything continuously

You now have a full, end-to-end **Agentic System template** that you can use in your trainings and real projects, and extend for other use cases like healthcare, sales, or operations.
