# 17. Types of Agents in LangChain

## 1. Simple Intro

By now you’ve seen **“an agent”** as:

- an LLM,
- plus tools,
- plus some rules/prompting,
- wrapped in an `AgentExecutor`.

But in real projects you don’t just have **one** kind of agent.  
You’ll see different **agent types / patterns**, each solving a different problem:

- a **simple tool-calling agent** that uses a few tools,
- **specialized agents** tuned for one job (SQL, retrieval, support),
- a **router agent** that picks *which* specialist to call,
- **planner/executor setups** for long, multi-step tasks,
- **graph / multi-agent** workflows when things get complex.

This chapter gives you a backend‑friendly map of these types so you can pick the right one instead of always using “one big agent”.

---

## 2. Why Backend Devs Should Learn This

As a backend developer, you already choose **controller patterns**:

- a simple controller for CRUD,
- a router that dispatches to different services,
- a workflow engine for long‑running jobs,
- background workers for heavy tasks.

Agent systems are similar:

- different **agent types** fit different workloads,
- the wrong type can be **slow, expensive, or fragile**,
- the right type is **simple to reason about and test**.

Knowing the main agent patterns in LangChain helps you:

- avoid over‑engineering with giant, “do everything” agents,
- keep prompts and tools focused on a single responsibility,
- design cleaner architectures (specialists + routers + workflows),
- ask Codex for **exactly the right pattern** when generating code.

---

## 3. Analogy: Different Kinds of Employees

Imagine running a company:

- **Generalist assistant** – can schedule meetings, answer emails, do light research.
- **Specialist** – accountant, lawyer, data analyst; deep expertise in one area.
- **Receptionist / router** – listens to the request and decides which specialist to send it to.
- **Project manager** – breaks a large project into tasks, assigns work, and tracks progress.
- **Operations lead** – coordinates *many* people across departments with a well‑defined process.

In LangChain terms:

- **Simple tool-calling agent** ≈ generalist assistant with a toolbox.
- **Specialized agent** ≈ one department expert (e.g., SQL, RAG).
- **Router agent** ≈ receptionist that chooses the right expert.
- **Planner + executor** ≈ project manager + workers.
- **Graph / multi-agent workflow** ≈ operations lead coordinating a whole process.

You don’t hire only one super‑employee for everything;  
you **compose roles**. Same idea for agent types.

---

## 4. Key Ideas About Agent Types

There isn’t a single “official” taxonomy, but most practical LangChain agents fall into a few patterns:

1. **Simple Tool-Calling Agents**
   - One `ChatOpenAI` model + a **small set of tools**.
   - Use LangChain’s `create_tool_calling_agent` and `AgentExecutor`.
   - Great for: support assistants, internal helpers, small backoffice tasks.

2. **Specialized Domain Agents**
   - Same tool-calling pattern, but tools and prompts are focused on **one domain**:
     - SQL / analytics,
     - retrieval / RAG,
     - ticketing / support,
     - devops / monitoring.
   - Easier to test and control than a huge “everything” agent.

3. **Router Agents**
   - An LLM that **chooses which sub-agent or chain to call**.
   - The router itself is simple; it reads the request and routes to:
     - `support_agent`,
     - `analytics_agent`,
     - `devops_agent`, etc.
   - This keeps each specialist small while giving users a single entrypoint.

4. **Planner / Executor Agents**
   - A **planner** agent turns a fuzzy request into a list of steps.
   - An **executor** (or a set of tools/agents) carries out those steps.
   - Useful for:
     - multi‑step business workflows,
     - report generation,
     - complex data pipelines.

5. **Graph / Multi-Agent Workflows (LangGraph)**
   - When control flow is complex (loops, retries, branching, state),  
     you model it as a **graph**:
     - nodes = agents/tools/LLM calls,
     - edges = transitions.
   - Gives you explicit control, better debuggability, and the ability to coordinate many agents.

You can build all of these with LangChain Core, often with LangGraph on top for the more complex ones.

---

## 5. Step-by-Step: Choosing the Right Agent Type

Here’s a practical way to decide what to use in a new feature.

### Step 1: Start with a Simple Tool-Calling Agent

- One agent, a handful of tools, one clear responsibility.
- Example: **support agent** that:
  - looks up tickets,
  - drafts reply emails,
  - summarizes long messages.

Benefits:

- easiest to build and debug,
- clear prompts and small tool surface area,
- an obvious place to add tests.

### Step 2: Split Into Specialized Agents When Responsibilities Diverge

If your one agent starts handling **very different** tasks:

- support,
- analytics,
- devops,
- data entry,

then:

- break it into **multiple specialized agents**, e.g.:
  - `support_agent`,
  - `analytics_agent`,
  - `devops_agent`.
- give each its own tools, prompts, and tests.

### Step 3: Add a Router Agent at the Front Door

Once you have specialists:

- users still want **one API endpoint**,
- you don’t want clients to decide *which* agent to call.

Add a **router** that:

- looks at the request,
- chooses the right specialist,
- forwards the request and returns the result.

The router itself can be:

- a small LLM chain,
- or a simple rules engine for obvious cases.

### Step 4: Use Planner / Executor When Tasks Get Long

For requests like:

> “Audit the last quarter’s sales data, find anomalies, and draft an executive summary.”

you often need:

- a **plan** (figure out subtasks),
- then **execution** (run tools/agents per subtask),
- then **aggregation** (combine results).

Here you can:

- create a **planner chain/agent** that outputs a list of steps,
- iterate through steps, calling tools or sub‑agents,
- track progress and intermediate results in state (LangGraph helps here).

### Step 5: Move to Graph / Multi-Agent Workflows for Complex Processes

When your logic has:

- loops (“keep asking until data is valid”),
- retries,
- multiple agents hand‑off (support → billing → compliance),
- long‑running jobs,

use **LangGraph** to:

- define nodes (agents/tools),
- define edges (who runs next, based on state),
- persist state between steps if needed.

You’re still using the same basic agent building blocks;  
you’re just composing them into a more explicit workflow.

---

## 6. Short Code Examples

These examples are simplified to show the **patterns**, not production‑ready code.

### Example 1: Simple Tool-Calling Support Agent

```python
# agents/support_agent.py
from typing import List

from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain.agents import AgentExecutor, create_tool_calling_agent

from tools.ticket_tools import get_ticket_by_id, draft_reply_email


def create_support_agent(model_name: str = "gpt-4.1-mini") -> AgentExecutor:
    llm = ChatOpenAI(model=model_name)
    tools: List = [get_ticket_by_id, draft_reply_email]

    prompt = ChatPromptTemplate.from_messages([
        ("system",
         "You are a support assistant.\n"
         "Use tools to inspect tickets and draft clear, friendly replies."),
        ("user", "{input}")
    ])

    agent = create_tool_calling_agent(llm, tools, prompt)
    return AgentExecutor(agent=agent, tools=tools)
```

This is the classic **single, simple tool-calling agent**.

---

### Example 2: Router Agent Calling Specialized Agents

```python
# agents/router_agent.py
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

from agents.support_agent import create_support_agent
from agents.analytics_agent import create_analytics_agent


router_llm = ChatOpenAI(model="gpt-4.1-mini")

router_prompt = ChatPromptTemplate.from_messages([
    ("system",
     "You are a router.\n"
     "Decide whether the user needs 'support' or 'analytics'.\n"
     "Answer with exactly one word: support or analytics."),
    ("user", "{input}")
])


def route_request(user_input: str) -> dict:
    chain = router_prompt | router_llm
    decision = chain.invoke({"input": user_input}).content.strip().lower()

    if "analytics" in decision:
        agent = create_analytics_agent()
    else:
        agent = create_support_agent()

    return agent.invoke({"input": user_input})
```

Here:

- the **router** is just an LLM + prompt,
- it decides which specialized agent to use,
- callers see only one function: `route_request`.

---

### Example 3: Very Simple Planner / Executor Pattern

```python
# agents/planner_executor.py
from typing import List, Dict

from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

from agents.support_agent import create_support_agent
from agents.analytics_agent import create_analytics_agent


planner_llm = ChatOpenAI(model="gpt-4.1-mini")

planner_prompt = ChatPromptTemplate.from_messages([
    ("system",
     "You are a project planner. Break the user's request into\n"
     "a numbered list of small, concrete steps. Keep steps short."),
    ("user", "{input}")
])


def plan_steps(user_input: str) -> List[str]:
    chain = planner_prompt | planner_llm
    response = chain.invoke({"input": user_input}).content
    steps = []
    for line in response.splitlines():
        line = line.strip()
        if not line:
            continue
        # naive parsing like "1. Do X"
        if line[0].isdigit():
            _, _, rest = line.partition(".")
            steps.append(rest.strip() or line)
        else:
            steps.append(line)
    return steps


def execute_plan(user_input: str) -> Dict:
    steps = plan_steps(user_input)

    support = create_support_agent()
    analytics = create_analytics_agent()

    results = []
    for step in steps:
        # Very naive routing based on keywords
        if any(word in step.lower() for word in ["ticket", "email", "customer"]):
            result = support.invoke({"input": step})
        else:
            result = analytics.invoke({"input": step})
        results.append({"step": step, "result": result.get("output", "")})

    return {
        "original_request": user_input,
        "steps": results,
    }
```

This shows:

- a **planner** (`plan_steps`) that creates a list of steps,
- an **executor** (`execute_plan`) that routes each step to a specialist,
- a natural path toward a **graph‑based** implementation later.

---

## 7. How Codex Helps

Codex is especially helpful when you want to **move between agent types** without rewriting everything by hand.

You can ask Codex to:

- **Split a monolithic agent into specialists**
  - “Take this single support agent and split it into `support_agent`, `billing_agent`, and `analytics_agent` with separate tools and prompts.”

- **Introduce a router**
  - “Create a router module that looks at the user input and chooses which agent to call. Start with simple keyword routing, then add an LLM‑based router.”

- **Add a planner layer**
  - “Add a planner that turns a request into a list of steps, and then call our existing agents/tools for each step. Keep the planner logic in `agents/planner_executor.py`.”

- **Upgrade to LangGraph**
  - “Given these agents and this planner, create a LangGraph workflow where each node is a step, with state carrying the intermediate results.”

- **Refactor prompts and tools per agent type**
  - “For each specialized agent, tighten the system prompt so it only answers in its domain, and adjust tool descriptions to be domain‑specific.”

Codex reads your repo, sees existing agents/tools/chains, and proposes patches that **respect your structure** while changing the agent architecture.

---

## 8. Small Diagram

### Types of Agents Working Together

```text
              ┌───────────────────────────┐
              │       Router Agent        │
              │ (LLM decides destination) │
              └─────────────┬─────────────┘
                            │
      ┌─────────────────────┼─────────────────────┐
      ↓                     ↓                     ↓
┌───────────────┐    ┌───────────────┐    ┌─────────────────┐
│ Support Agent │    │ Analytics     │    │ Other Specialist │
│ (tools:       │    │ Agent         │    │ Agents           │
│  tickets,     │    │ (SQL, reports)│    │ (RAG, devops, …)│
└───────────────┘    └───────────────┘    └─────────────────┘
                            ↓
                        (optional)
                            ↓
                    ┌───────────────┐
                    │ Planner /     │
                    │ LangGraph     │
                    │ Workflow      │
                    └───────────────┘
```

### From Simple Agent to Full Workflow

```text
[Single Tool-Calling Agent]
           ↓
[Multiple Specialized Agents]
           ↓
[Router Agent in Front]
           ↓
[Planner + Executor]
           ↓
[Graph / Multi-Agent Workflow (LangGraph)]
```

You don’t need to jump to graphs on day one;  
you evolve from simple agents to more structured types as requirements grow.

---

## 9. Summary

- LangChain doesn’t give you just “one agent”; it supports several **agent types/patterns**:
  - simple tool-calling agents,
  - specialized domain agents,
  - router agents,
  - planner/executor setups,
  - graph / multi-agent workflows with LangGraph.
- Choosing the right type is like choosing the right controller/workflow pattern in a normal backend:
  - start with a simple agent,
  - split into specialists,
  - add a router,
  - introduce planning,
  - then move to graphs when flows are complex.
- Codex makes it easy to **refactor between these types** by:
  - splitting agents,
  - adding routers and planners,
  - wiring everything into LangGraph as your system matures.
- With a clear mental model of agent types, you can design agentic systems that are **simpler, safer, and easier to evolve** over time.

