# **Chapter 31. Using LangServe**

### **1. Simple Introduction**

LangServe is a small, helpful tool that lets you turn your **agents** (the ones you build with LangChain or LangGraph) into **web services**.
This means other apps, your frontend, mobile clients, or even other microservices can call your agent through simple HTTP requests (GET or POST).

Think of LangServe as a **bridge**:

* Left side → your agent’s logic
* Right side → a clean API endpoint that anyone can call

This makes your agent usable just like any other backend service.

---

### **2. Real-Life Analogy**

Imagine you have a smart assistant sitting in your office who can do tasks—summarize documents, answer questions, run workflows.

But your team members are in different rooms.

So you put a **phone** on the assistant’s desk.

Now anyone can:

* Call the assistant
* Tell what they need
* Get the response

LangServe is exactly that phone.
It lets *other programs* talk to your agent.

---

### **3. Why We Use LangServe**

* To expose an agent as an API endpoint
* To let your frontend call the agent
* To connect different business systems
* To run agents inside a microservice architecture
* To make the agent usable from Python, JavaScript, mobile apps, n8n, etc.

---

### **4. Setup (Simple Steps)**

Install LangServe:

```bash
pip install langserve langchain langchain-openai fastapi uvicorn
```

---

### **5. Turning an Agent Into a Web Service**

Below is the simplest way to expose an agent using FastAPI + LangServe.

#### **Step 1 — Create an agent**

```python
# agent.py
from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage

llm = ChatOpenAI(model="gpt-4o-mini")

async def run_agent(message: str):
    response = await llm.ainvoke([HumanMessage(content=message)])
    return response.content
```

This agent just takes a message and replies.

---

#### **Step 2 — Expose it using LangServe**

```python
# server.py
from fastapi import FastAPI
from langserve import add_routes
from agent import run_agent

app = FastAPI()

add_routes(
    app,
    run_agent,       # your agent function
    path="/agent"    # API endpoint
)
```

---

#### **Step 3 — Run the service**

```bash
uvicorn server:app --reload --port 8000
```

Now your agent is available at:

```
http://localhost:8000/agent
```

---

### **6. Calling the Agent with POST**

Your client (frontend/mobile/another microservice) can send data like this:

```bash
curl -X POST http://localhost:8000/agent \
  -H "Content-Type: application/json" \
  -d '{"input": "Hello agent, help me summarize this"}'
```

The response will be JSON:

```json
{
  "output": "Sure! Here is the summary..."
}
```

---

### **7. Calling the Agent with GET (simpler)**

If your agent doesn’t take complicated input:

```bash
curl "http://localhost:8000/agent?input=Hello"
```

LangServe converts the GET request into a call to your agent.

---

### **8. Step-by-Step Example: Symptom Summary Agent**

Let’s expose a simple healthcare-safe agent that summarizes patient symptoms.

#### Agent:

```python
# symptom_agent.py
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(model="gpt-4o-mini")

async def symptom_summarizer(symptoms: str):
    prompt = f"""
    Patient symptoms (as reported):
    {symptoms}

    Create a simple, safe summary (no diagnosis).
    """

    response = await llm.ainvoke(prompt)
    return {"summary": response.content}
```

#### Server:

```python
# server.py
from fastapi import FastAPI
from langserve import add_routes
from symptom_agent import symptom_summarizer

app = FastAPI()

add_routes(app, symptom_summarizer, "/symptom-summary")
```

#### POST request:

```bash
curl -X POST http://localhost:8000/symptom-summary \
  -H "Content-Type: application/json" \
  -d '{"input": "burning sensation while urinating for 2 days"}'
```

#### Output:

```json
{
  "output": {
    "summary": "Patient reports a burning sensation during urination for about 2 days..."
  }
}
```

---

### **9. Simple Diagram**

```
Your Agent Logic
      |
      v
[ LangServe ]
      |
      v
HTTP API (GET/POST)
      |
      v
Frontend / n8n / Mobile App / Other Services
```

---

### **10. Common Use Cases**

* **Chatbots** exposed as `/chat` endpoints
* **Healthcare agents** exposed as `/symptom-summary`
* **Business workflow agents** exposed as `/report-generator`
* **Document QA agents** exposed as `/qa`
* **AI-powered microservices** inside larger systems

---

### **11. Summary**

LangServe makes it very easy to:

* Take any agent you build
* Wrap it inside a FastAPI service
* Expose it via GET/POST
* Use it from any application

This is the simplest and cleanest way to turn your agent into a reliable **microservice**.

---
