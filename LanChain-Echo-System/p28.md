# 28. Customer Support Agent

## 1. Introduction

A customer support agent is an AI assistant that can read customer questions in natural language, understand what they need, look up information in your systems, and reply in a clear, friendly way.  
Instead of a rigid chatbot with `if / else` rules, this agent can think step by step, call your APIs when needed, and then explain the result like a human support rep.

---

## 2. Why backend developers should care

- Support teams spend a lot of time answering the same simple questions (order status, refunds, password issues).  
- You already own the data and services the agent must use: orders, users, payments, tickets.  
- You know how to enforce auth, rate limits, logging, and data privacy.  
- By exposing your existing backend as tools, you can ship a useful support agent quickly without rewriting your system.  
- Over time, you can add more tools and better prompts the same way you’d evolve any backend service.

---

## 3. Real-life analogy

Imagine a busy store with:

- A **front desk person** who talks to customers.  
- Several **internal desks**:
  - Orders desk  
  - Billing desk  
  - Returns / refunds desk  
  - A big binder of FAQ and policies

Now imagine a **super assistant**:

- Listens to the customer’s story.  
- Decides which desk to visit (Orders? Billing? The FAQ binder?).  
- Walks over, asks questions or reads the binder.  
- Comes back and explains the answer in simple language.

In our system:

- The **agent** = the super assistant.  
- Each **tool** = one of those desks or systems (order API, ticket API, FAQ search).  
- **Memory** = the notebook the assistant uses to remember the conversation.  
- A **vector DB** = the smart bookshelf where FAQ pages are stored so similar questions are easy to find.

---

## 4. Key concepts

- **Agent**  
  The “brain” that:
  - Reads the user message.  
  - Decides whether to answer directly or call tools.  
  - Chooses which tool to call and how to use the result.  
  - Returns the final answer.

- **Tool**  
  A small function or microservice the agent can call, for example:
  - `get_order_status(order_id)`  
  - `create_support_ticket(user_id, message)`  
  - `search_faq(question_text)`  
  Tools are just your normal backend logic, wrapped so the agent can use them.

- **Embeddings**  
  A way to turn text into numbers (vectors).  
  Texts with similar meaning (e.g., “refund policy” and “money back rules”) end up with similar vectors.

- **Vector DB**  
  A database specialized for these vectors.  
  It can quickly find the FAQ chunks most related to a new question, even if the wording is different.

- **RAG (Retrieval-Augmented Generation)**  
  A pattern where the agent:
  1. Uses embeddings to search relevant FAQ or policy docs in the vector DB.  
  2. Reads those docs.  
  3. Writes an answer that cites or follows those docs.

- **Memory**  
  Stores previous messages in the conversation, so the agent remembers:
  - Who the user is.  
  - Which order ID they already mentioned.  
  - What has already been answered.

- **LangChain**  
  A framework that helps you:
  - Define tools.  
  - Create agents that can call tools.  
  - Plug in memory and retrieval.  
  - Connect everything to OpenAI models with minimal boilerplate.

---

## 5. Steps explained simply

### Step 1 – List top support tasks

Write down the 5–10 most common questions:

- “Where is my order?”  
- “How do I reset my password?”  
- “What is your refund policy?”  
- “Can I change my shipping address?”  
- “I want to talk to a human.”

These will guide which tools and documents you need first.

---

### Step 2 – Wrap your backend as tools

Take your existing endpoints / queries:

- `GET /orders/{id}`  
- `POST /tickets`  
- `GET /users/{id}`  

and turn them into Python functions that LangChain can expose as tools.  
Each tool:

- Has clear parameters (e.g., `order_id: str`).  
- Calls your DB or REST API.  
- Returns a short, structured result or a friendly string.

---

### Step 3 – Build an FAQ knowledge base

1. Collect content: help center articles, FAQ pages, refund/shipping policies.  
2. Split into small chunks (e.g., each paragraph or section).  
3. Use an embedding model to convert each chunk into a vector.  
4. Store vectors + text in a vector DB (like Chroma or pgvector).  
5. Expose a `search_faq` tool that:
   - Takes a question.  
   - Searches the vector DB.  
   - Returns the top few relevant chunks.

---

### Step 4 – Create the support agent with LangChain

Connect a chat model to your tools:

- Define a **system prompt** like:  
  “You are a polite customer support agent for OurShop. Use tools to fetch real data. If unsure, ask for clarification or escalate to a human.”
- Pass the tools list (order status, ticket creation, FAQ search) to the agent.  
- Let the agent decide at runtime:
  - whether to answer directly,  
  - or which tool(s) to call.

---

### Step 5 – Add conversation memory

Add a memory component so the agent remembers the session:

- Store the recent messages and tool results.  
- When the user says “What about order 456?” the agent can connect it to the earlier part of the conversation.  
- Memory can be in-memory for small demos or Redis/DB for production sessions.

---

### Step 6 – Expose a `/support/chat` endpoint

Wrap everything in an API:

- `POST /support/chat`
  - Request: `{ "user_id": "u123", "message": "Where is my order 789?" }`  
  - Backend:
    - Loads conversation memory for this user.  
    - Calls the agent with message + tools + memory.  
    - Stores updated memory.  
  - Response: `{ "reply": "...agent answer..." }`

Your frontend widget (web, mobile, admin portal) just sends messages to this endpoint and displays the reply.

---

### Step 7 – Logging, safety, and escalation

- Log every conversation, tool call, and final answer.  
- Enforce permissions before tools run (e.g., user can only see their own orders).  
- Put hard limits around actions that change data.  
- If the agent is unsure, let it create a ticket and tell the user a human will follow up.

---

## 6. Short code examples

### 6.1 Tools for orders and tickets

```python
from langchain_core.tools import tool


@tool
def get_order_status(order_id: str) -> str:
    """Return the status of a given order."""
    # Real code: call your DB or REST API here.
    fake_db = {
        "123": "Shipped on 2025-01-10",
        "456": "Processing in warehouse",
    }
    status = fake_db.get(order_id)
    if not status:
        return f"Order {order_id} not found."
    return f"Order {order_id} status: {status}"


@tool
def create_ticket(email: str, message: str) -> str:
    """Create a support ticket and return its ID."""
    # Real code: call your ticket system here.
    ticket_id = "TCK-1001"
    return f"Created ticket {ticket_id} for {email} with message: {message}"
```

### 6.2 FAQ retrieval tool (conceptual)

```python
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain_core.tools import tool


embeddings = OpenAIEmbeddings()
vector_store = Chroma(
    collection_name="faq",
    embedding_function=embeddings,
)
retriever = vector_store.as_retriever(search_kwargs={"k": 3})


@tool
def search_faq(query: str) -> str:
    """Search FAQ content and return useful snippets."""
    docs = retriever.get_relevant_documents(query)
    if not docs:
        return "No relevant FAQ entries found."
    return "\n\n".join(d.page_content for d in docs)
```

### 6.3 Wiring tools into an agent

```python
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain.agents import create_openai_tools_agent, AgentExecutor


tools = [get_order_status, create_ticket, search_faq]

model = ChatOpenAI(
    model="gpt-4o-mini",  # any chat-capable model
    temperature=0.2,
)

prompt = ChatPromptTemplate.from_messages(
    [
        ("system",
         "You are a helpful, polite customer support agent for OurShop. "
         "Use tools to fetch real data and follow company policies."),
        ("human", "{input}"),
        ("ai", "{agent_scratchpad}"),
    ]
)

agent = create_openai_tools_agent(model, tools, prompt)
agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)


def ask_support_agent(message: str) -> str:
    result = agent_executor.invoke({"input": message})
    return result["output"]
```

---

## 7. How Codex helps

OpenAI Codex (and similar code-focused models) can speed up this whole process:

- **Generate tool wrappers**  
  - Give Codex your OpenAPI spec or SQL schema.  
  - Ask it to generate Python functions + `@tool` wrappers for orders, billing, tickets, etc.

- **Scaffold the chat API**  
  - Have Codex write the FastAPI / Flask route for `/support/chat`, including request models, error handling, and logging.

- **Build the RAG pipeline**  
  - Use Codex to:
    - Load and split FAQ documents.  
    - Create embeddings and store them in a vector DB.  
    - Implement the `search_faq` tool.

- **Testing and refactoring**  
  - Ask Codex to generate unit tests for each tool.  
  - Let it refactor messy glue code and improve naming and docstrings as the project grows.

Codex is like a fast backend pair programmer that handles boilerplate so you can focus on real support logic and data rules.

---

## 8. Small diagram

High-level architecture:

```text
User → Frontend Chat Widget → Backend `/support/chat` API
                                  ↓
                            [Support Agent]
                                  ↓
              ┌───────────────────────────────┬───────────────────┐
              ↓                               ↓                   ↓
      [Order Status Tool]              [FAQ Search]        [Ticket Tool]
            (DB/API)                   (Vector DB)         (Ticket System)
```

Reasoning flow:

```text
[User Question]
      ↓
[Agent reads and interprets]
      ↓
[Need data?] ── no ──► [Answer directly]
      │
     yes
      ↓
[Call tools (orders / FAQ / tickets)]
      ↓
[Combine tool results + docs]
      ↓
[Generate friendly answer]
      ↓
[Send reply to user]
```

---

## 9. Summary

- A customer support agent is a smart assistant that understands questions, calls your backend tools, and replies in natural language.  
- As a backend developer, you already have most of the pieces: APIs, databases, and auth.  
- LangChain lets you turn those pieces into tools, add memory, and plug in retrieval from a vector DB for FAQ content.  
- Embeddings and a vector DB give “search by meaning” over your help center and policy docs.  
- Codex can generate, refactor, and test the surrounding code so you can deliver a useful support agent faster and keep improving it over time.

