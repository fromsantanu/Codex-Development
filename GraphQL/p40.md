# Chapter 40. Using DataLoader / Batching

---

### 1. Introduction

In the last chapter, we saw the **N+1 problem**:
too many small database calls inside GraphQL resolvers.

**DataLoader** is a small helper library (by Facebook) that:

* Collects many similar requests.
* Groups them into **one batch**.
* Calls the database **once** with all the needed IDs.
* Then returns the right result to each resolver.

Think of DataLoader as a **smart delivery boy** who waits a moment,
collects all orders for the same shop, and then makes **one trip**.

---

### 2. Why this matters

You should care about DataLoader because:

* It reduces **N+1 queries** to **1 or 2 queries**.
* It makes your API **faster** when data grows.
* It keeps resolver code **clean**: you call `loader.load(id)` instead of writing SQL everywhere.

In a real system (clinic, shop, school),
DataLoader can be the difference between **OK performance** and **very slow**.

---

### 3. Real-life example (Grocery Categories)

Again, imagine an **online grocery app**:

* A GraphQL query asks:
  “Give me all grocery items with their categories.”

Without DataLoader:

* For each item, you call the DB to get its category.
* 1 query for items + N queries for categories.

With DataLoader:

* All category requests are **collected**.
* DataLoader calls the DB once:
  “Give me categories for IDs: 1, 2, 3, 4…”
* It then **maps** each category back to the right item.

Result: **fast and clean**.

---

### 4. Code Examples

We will use **Node.js**, **Apollo Server**, and the **dataloader** npm package.

#### 4.1 Simple schema (same as before)

```graphql
# schema.graphql
type Category {
  id: ID!
  name: String!
}

type GroceryItem {
  id: ID!
  name: String!
  category: Category!
}

type Query {
  groceryItems: [GroceryItem!]!
}
```

---

#### 4.2 Installing DataLoader

```bash
npm install dataloader
```

---

#### 4.3 Creating a Category DataLoader

Idea:

* DataLoader takes a function that receives **an array of keys** (IDs).
* You make **one DB call** using all those keys.
* Return an array of results **in the same order** as the keys.

```js
// loaders/categoryLoader.js
const DataLoader = require('dataloader');

// batch function: keys = [categoryId1, categoryId2, ...]
async function batchCategories(keys) {
  // keys is an array of category IDs
  // Example: [1, 2, 3, 2]

  // 1. Query DB once for all these IDs
  const categories = await db.categories.findByIds(keys);
  // Suppose this returns: [{ id: 1, ...}, { id: 2, ...}, { id: 3, ...}]

  // 2. Build a map from id -> category
  const categoryMap = new Map();
  for (const cat of categories) {
    categoryMap.set(cat.id, cat);
  }

  // 3. Return results in the same order as keys
  // If the same key appears twice, DataLoader will handle caching.
  return keys.map((key) => categoryMap.get(key) || null);
}

function createCategoryLoader() {
  return new DataLoader(batchCategories);
}

module.exports = {
  createCategoryLoader,
};
```

Simple English comments:

* Take all IDs together.
* Call the DB once.
* Put the results in a map.
* Return them in the same order.

---

#### 4.4 Adding DataLoader to GraphQL context

We create loaders for each request
(so cache is per-request, not global):

```js
// server.js
const { ApolloServer } = require('@apollo/server');
const { createCategoryLoader } = require('./loaders/categoryLoader');
const typeDefs = require('./schema');
const resolvers = require('./resolvers');

const server = new ApolloServer({
  typeDefs,
  resolvers,
});

async function start() {
  // ... usual server startup code
  // Example using Apollo Server with a context function:

  const apolloServer = new ApolloServer({
    typeDefs,
    resolvers,
  });

  // When handling each request:
  const context = async () => {
    return {
      loaders: {
        categoryLoader: createCategoryLoader(),
      },
    };
  };

  // Pass context to your server integration (Express, etc.)
}

start();
```

Key idea:

* Each request gets its own `categoryLoader`.
* Inside resolvers, you call `context.loaders.categoryLoader.load(id)`.

---

#### 4.5 Resolvers using DataLoader (GOOD)

```js
// resolvers.js
const resolvers = {
  Query: {
    groceryItems: async () => {
      // 1 DB call: get all items
      return db.groceryItems.findAll();
    },
  },

  GroceryItem: {
    category: async (parent, _args, context) => {
      // Instead of hitting the DB directly,
      // we ask DataLoader to load this category.
      // DataLoader will batch multiple calls.
      return context.loaders.categoryLoader.load(parent.categoryId);
    },
  },
};

module.exports = resolvers;
```

What happens:

* Many `GroceryItem.category` resolvers run.
* Each calls `categoryLoader.load(parent.categoryId)`.
* DataLoader **collects** all these IDs.
* It calls `batchCategories(keys)` once.
* It distributes the results back to each resolver.

So inside one GraphQL request:

```text
Before: 1 query for items + N queries for categories
After : 1 query for items + 1 query for all categories used
```

---

#### 4.6 Another example: clinic with patients and visits

Same idea works for a clinic app:

* Query: `patients { id name visits { id date } }`
* Use a `visitLoader` that batches `patientId` keys.
* DB call: `SELECT * FROM visits WHERE patient_id IN (...)`.

The pattern is always:

1. Create a DataLoader for related data.
2. Put it in `context.loaders`.
3. In field resolvers, call `loader.load(key)`.

---

### 5. Simple Diagram

**Without DataLoader**

```text
GraphQL Request
    |
    v
Query.groceryItems  ------> DB: 1 query (all items)
    |
    +--> GroceryItem.category (runs N times)
             |
             +--> DB: 1 query per item (N queries)
Total: 1 + N DB queries
```

**With DataLoader**

```text
GraphQL Request
    |
    v
Query.groceryItems  ------> DB: 1 query (all items)
    |
    +--> GroceryItem.category (runs N times)
             |
             +--> DataLoader.load(categoryId)
                       |
                       +--> batchCategories([...keys...])
                                 |
                                 +--> DB: 1 query for all categories
Total: 2 DB queries
```

---

### 6. How to Instruct Codex to Automate This

Here are prompts you can copy–paste to use Codex as your assistant.

1. **Main prompt from this chapter**

> **Prompt 1**
> “Add DataLoader to these resolvers to batch loading of related entities, and comment each step in simple English.”

2. **Convert existing resolvers to use DataLoader**

> **Prompt 2**
> “Here is my GraphQL schema and resolvers for grocery items and categories. Replace the direct DB calls in the GroceryItem.category resolver with a DataLoader that batches category ID lookups. Explain each step in comments.”

3. **Clinic example with patients and visits**

> **Prompt 3**
> “I have a GraphQL API for a clinic with Patient and Visit types. Show how to create a Visit DataLoader that batches patientId lookups, and update the resolvers to use it. Use simple comments for each line.”

4. **Multi-entity loaders in one context**

> **Prompt 4**
> “Generate a context factory that creates DataLoaders for categories, suppliers, and brands in a grocery app, and update the resolvers to use these loaders instead of calling the database directly.”

5. **Detect and fix N+1 using DataLoader**

> **Prompt 5**
> “Look at these resolvers and tell me where the N+1 problem can happen. Then add DataLoader-based batching to fix it, with the batch functions and resolver changes written in clear, commented JavaScript.”

---

### 7. Summary

1. **DataLoader** helps you avoid the N+1 problem by **batching many small loads** into **one grouped query**.
2. You create a loader with a batch function, attach it to the **context**, and call `loader.load(key)` in your field resolvers.
3. This makes your GraphQL API **faster**, **cleaner**, and **more scalable**, especially in real apps like grocery stores, clinics, and schools.

