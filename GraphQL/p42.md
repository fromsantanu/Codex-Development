# Chapter 42. Server Caching vs Client Caching

---

### 1. Introduction

Caching is like **storing a ready-made answer** so we don‚Äôt calculate it again.
In GraphQL, caching can happen in two places:

* **Client-side caching** ‚Üí Browser or frontend stores results locally.
* **Server-side caching** ‚Üí Backend stores results to avoid re-running heavy work.

Both are useful.
Both save time.
But they are used in **different situations**.

---

### 2. Why this matters

A GraphQL query may:

* Fetch big data.
* Hit multiple microservices.
* Perform expensive calculations (e.g., ML scoring, analytics).
* Read data that rarely changes.

Caching can:

* Make these queries fast.
* Reduce load on servers and databases.
* Improve user experience.

Good developers know:
**What to cache, where to cache, and for how long.**

---

### 3. Real-life examples (Very simple stories)

#### üõí Grocery App Example

You have a page called **"Top Selling Items"**.
It changes only **once every 24 hours**.

* If 500 users open the app, server might compute the same thing 500 times.
* Better: let the **server cache** the result for 24 hours.

#### üè• Clinic App Example

A query shows **"Monthly Patient Summary"** (counts, charts).
This changes only once per day.

* Server caches this.
* Frontend gets instant results.

#### üì± Mobile App Example

When the same user moves between screens, the frontend caches GraphQL queries like:

```graphql
query {
  me {
    id
    name
    role
  }
}
```

This data doesn‚Äôt change often, so client-side caching (Apollo Client, React Query) is perfect.

---

### 4. Server Caching vs Client Caching (Simple Comparison)

| Feature       | Server-side Caching                                | Client-side Caching                        |
| ------------- | -------------------------------------------------- | ------------------------------------------ |
| Stored where? | On the backend (Redis, memory, DB table)           | On the user‚Äôs device/browser               |
| Best use      | Heavy queries, expensive computations, shared data | Small queries, user-specific data          |
| Helps who?    | All users (shared benefit)                         | Only that user                             |
| Lifetime      | Minutes, hours, days                               | Until reload or cache invalidation         |
| Example       | Top 100 grocery items, monthly analytics           | Logged-in user profile, last list of items |

---

### 5. Code Example ‚Äì Server-side caching (Node + Apollo + Redis)

Below is a **simple** example to show the idea.

#### 5.1 Install Redis client

```bash
npm install redis
```

---

#### 5.2 Example heavy GraphQL query (Top Selling Items)

```graphql
type TopItem {
  id: ID!
  name: String!
  sold: Int!
}

type Query {
  topSellingItems: [TopItem!]!
}
```

Assume this query normally:

* Runs a heavy SQL aggregation.
* Takes 1‚Äì3 seconds.

Perfect candidate for **server caching**.

---

#### 5.3 Resolver WITHOUT caching (slow every time)

```js
// heavyResolvers.js
const resolvers = {
  Query: {
    topSellingItems: async () => {
      // Heavy DB call every time
      return db.items.getTopSellingItems();
    },
  },
};
```

---

#### 5.4 Add server-side caching using Redis

```js
// resolversWithCache.js
const redis = require('redis');
const client = redis.createClient();

// Connect Redis client
client.connect();

const CACHE_KEY = "top_selling_items";
const CACHE_DURATION = 60 * 60 * 24; // 24 hours in seconds

const resolvers = {
  Query: {
    topSellingItems: async () => {
      // 1. Check Redis cache first
      const cached = await client.get(CACHE_KEY);
      if (cached) {
        // Convert cached string back to JSON
        return JSON.parse(cached);
      }

      // 2. If not cached, run heavy DB aggregation
      const result = await db.items.getTopSellingItems();

      // 3. Store result in Redis for 24 hours
      await client.set(CACHE_KEY, JSON.stringify(result), {
        EX: CACHE_DURATION,
      });

      return result;
    },
  },
};

module.exports = resolvers;
```

#### Explanation in simple English

* Before doing the heavy work, we ask Redis:
  **‚ÄúDo you already have this answer stored?‚Äù**
* If yes ‚Üí return stored result immediately.
  (Very fast, almost no database work.)
* If no ‚Üí run the heavy DB query.
* Then store the result in Redis for 24 hours.
* Next 1000 requests ‚Üí served from cache.

---

### 6. Client-side caching (with Apollo Client)

Client-side caching is automatically handled by tools like **Apollo Client**.

Example:

```js
import { gql, useQuery } from '@apollo/client';

const GET_ME = gql`
  query {
    me {
      id
      name
      role
    }
  }
`;

export function Profile() {
  const { data } = useQuery(GET_ME);  // Apollo caches this automatically

  return <div>Hello {data.me.name}</div>;
}
```

Apollo will:

* Store the result in memory.
* Use cached value if query fields match.
* Automatically update if GraphQL returns new data.

This is perfect for:

* User profile
* Lists the user sees often
* Navigation between screens

But **server-side caching** handles heavy queries better.

---

### 7. Simple Diagram

```
          Client (Browser/App)
                |
         +---------------+
         | Client Cache  |
         | (Apollo)      |
         +---------------+
                |
         GraphQL Request
                |
       +-------------------+
       | GraphQL Server   |
       +-------------------+
                |
       +-------------------+
       | Server Cache      |
       | (Redis / Memory)  |
       +-------------------+
                |
              Database
```

---

### 8. When to use which? (Very simple rule)

#### Use **client-side caching** when:

* Data is small.
* Data belongs to one user.
* Data changes frequently but not needed fresh every second.
* Example: profile info, lists, navigation pages.

#### Use **server-side caching** when:

* Query is heavy or expensive.
* Same result is needed by **many** users.
* Data changes slowly (daily, hourly).
* Example: Top selling items, daily analytics, summary reports.

---

### 9. How to Instruct Codex to Automate This

Use these prompts directly:

1. **Main prompt from this chapter**

> **Prompt 1**
> ‚ÄúShow an example of server-side caching for a heavy GraphQL query and explain how it works with a real-life example.‚Äù

2. **Add caching to an existing resolver**

> **Prompt 2**
> ‚ÄúHere is my GraphQL resolver for a heavy query. Add Redis-based server caching with a 1-hour expiry and explain each step in simple English.‚Äù

3. **Grocery example**

> **Prompt 3**
> ‚ÄúAdd server-side caching to the ‚ÄòtopSellingItems‚Äô resolver in this grocery GraphQL API. Use Redis, add comments, and explain how the cache reduces load.‚Äù

4. **Compare server vs client caching**

> **Prompt 4**
> ‚ÄúGive me a simple explanation of when to use client-side caching and when to use server-side caching for a GraphQL grocery app.‚Äù

5. **Automatically generate cache invalidation logic**

> **Prompt 5**
> ‚ÄúAdd a simple cache invalidation rule to my GraphQL server: whenever an item is updated, clear the topSellingItems cache. Add comments.‚Äù

---

### 10. Summary

1. **Client caching** is for user-specific data, small results, fast UI updates.
2. **Server caching** is for heavy queries, reports, analytics, and shared data.
3. Together, they make GraphQL apps **faster**, **cheaper**, and **more scalable**.

