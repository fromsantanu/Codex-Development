# Chapter 43. GraphQL in High-Traffic Systems

---

### 1. Introduction

When your system becomes popular, many users start sending GraphQL queries at the same time.
If your API is not prepared, it may:

* Slow down
* Crash
* Make too many DB calls
* Consume too much memory

Scaling GraphQL simply means:
**“Handle more requests safely without breaking.”**

In this chapter, we look at simple, practical techniques that keep GraphQL stable during heavy traffic.

---

### 2. Why this matters

When traffic increases (more customers, more mobile users, more clinic staff):

* Each GraphQL request may trigger many resolver functions.
* Each resolver may call your database or microservices.
* Without good design, load grows faster than you expect.

Good scaling protects you from:

* High CPU usage
* High database load
* Slow response times
* Server crashes during peak hours

Even simple steps make a big difference.

---

### 3. Real-life example (Grocery Flash Sale)

Imagine a grocery app where:

* 5,000 users open the “Today’s Offers” page at 9 AM.
* All of them fire the same GraphQL query:

```graphql
query {
  discountedItems {
    id
    name
    price
    discount
  }
}
```

If each request:

* Runs full DB queries
* Performs multiple joins
* Fetches deep nested data

Your system may collapse.

But with good scaling techniques:

* Cache results
* Batch DB calls
* Limit query depth
* Use multiple servers with a load balancer
* Reduce unnecessary GraphQL overhead

The app stays stable.

---

### 4. 5 Practical Ways to Scale a GraphQL API

We cover the **five most important**, easy-to-understand techniques.

---

## **1. Use Server-Side Caching (Redis / Memory Cache)**

Heavy queries should not hit the DB every time.

Example (Redis):

```js
const redis = require("redis");
const client = redis.createClient();
await client.connect();

async function cachedDiscountedItems() {
  const cached = await client.get("discounted_items_cache");
  if (cached) return JSON.parse(cached);

  const result = await db.items.getDiscountedItems();
  await client.set("discounted_items_cache", JSON.stringify(result), { EX: 60 }); // 1 minute cache
  return result;
}
```

Simple explanation:

* If many users request the same query, serve from **cache**.
* Saves DB+CPU.
* Very effective during peak hours.

---

## **2. Use DataLoader to Avoid N+1 Database Calls**

High traffic + N+1 = disaster.

Example:

```js
const itemLoader = new DataLoader(async (ids) => {
  const rows = await db.items.findByIds(ids);
  const map = new Map(rows.map((r) => [r.id, r]));
  return ids.map((id) => map.get(id));
});
```

Then:

```js
GroceryItem: {
  details: (parent, _, ctx) => ctx.loaders.itemLoader.load(parent.itemId)
}
```

Simple explanation:

* Instead of many DB calls, everything is batched into **one query**.
* Lower DB load → scale easily.

---

## **3. Add Query Depth & Complexity Limits**

Prevents expensive “monster queries”.

Example:

```js
const MAX_DEPTH = 5;

plugins: [
  {
    async requestDidStart() {
      return {
        async didResolveOperation(ctx) {
          const ast = parse(ctx.request.query);
          const depth = getQueryDepth(ast);
          if (depth > MAX_DEPTH) throw new Error("Too deep!");
        }
      };
    }
  }
]
```

Why it matters:

* Hackers cannot send huge nested queries.
* Prevents CPU overload.
* Keeps server predictable.

---

## **4. Horizontal Scaling With Load Balancing**

Run **multiple GraphQL servers** behind a load balancer.

Simple Nginx example:

```nginx
upstream graphql_pool {
    server 10.0.0.1:4000;
    server 10.0.0.2:4000;
    server 10.0.0.3:4000;
}

server {
    listen 80;
    location /graphql {
        proxy_pass http://graphql_pool;
    }
}
```

Explanation:

* Requests are spread across several servers.
* If one server is busy, others help.
* Very effective when traffic is high.

---

## **5. Persisted Queries (Send Query Hash Instead of Full Query)**

Instead of sending full GraphQL queries:

* Store queries on the server.
* Client sends **just the hash**.

Example client-side call:

```json
{
  "id": "hash123",
  "variables": { "limit": 10 }
}
```

Benefits:

* Lowers network cost (especially on mobile).
* Reduces parsing work on the server.
* Protects against malicious queries (only known queries allowed).

---

### 5. Simple Diagram

```
                   High Traffic Users
                         |
              +--------------------+
              |   Load Balancer    |
              +--------------------+
          /           |           \
   +----------+  +----------+  +----------+
   | Server 1 |  | Server 2 |  | Server 3 |
   +----------+  +----------+  +----------+
       |             |             |
       |      (redis cache)        |
       +------>  Redis  <----------+
```

And inside each server:

```
Client Query
   |
[Persisted Query]  (optional)
   |
[Check Depth & Complexity]
   |
[Use DataLoader]
   |
[Use Server Cache]
   |
[DB]
```

---

### 6. How to Instruct Codex (Copy-Paste Prompts)

Use these directly:

#### **Prompt 1 — Main prompt**

> “List 5 practical ways to scale a GraphQL API for high traffic and give small code/config examples where useful.”

#### **Prompt 2 — Ask Codex to add scaling improvements to your code**

> “Look at my current GraphQL server code and suggest 5 improvements to handle high traffic. Add caching, DataLoader, depth limits, and load balancer config examples.”

#### **Prompt 3 — Convert heavy queries to cached resolvers**

> “Convert these heavy GraphQL resolvers to use Redis caching and write simple English comments explaining each step.”

#### **Prompt 4 — Add DataLoader automatically**

> “Refactor these resolvers to use DataLoader to avoid N+1 problems during high traffic. Explain batching logic.”

#### **Prompt 5 — Add production deployment setup**

> “Generate a production deployment plan for my GraphQL API with 3 servers behind Nginx load balancer and include Redis caching.”

---

### 7. Summary

1. High-traffic GraphQL systems need **caching**, **batching**, **limits**, and **horizontal scaling**.
2. DataLoader, Redis, and depth limits stop your server from overloading.
3. Load balancing allows many GraphQL servers to work together.
4. Persisted queries reduce parsing cost and increase safety.
5. Codex can help you **refactor**, **optimize**, and **configure** every part of this setup.

